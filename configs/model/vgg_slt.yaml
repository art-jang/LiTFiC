_target_: src.models.slt_module.SLTLitModule

optimizer:
  _target_: torch.optim.Adam
  _partial_: true
  lr: 0.0001
  weight_decay: 0.

scheduler:
  _target_: pl_bolts.optimizers.lr_scheduler.LinearWarmupCosineAnnealingLR
  _partial_: true
  warmup_epochs: 1
  max_epochs: ${trainer.max_epochs}
  warmup_start_lr: 0

scheduler_options:
  monitor: val/loss
  frequency: 1
  interval: step # epoch
  divide_step: ${trainer.accumulate_grad_batches}

net:
  _target_: src.models.components.vgg_slt.VggSLTNet
  load_features: ${data.dataset_config.load_features}
  precision: ${trainer.precision}
  visual_encoder_config:
    encoder_type: null
    out_dim: 768
  mm_projector_config:
    mm_hidden_size: ${model.net.visual_encoder_config.out_dim}
    hidden_size: 3072
    projector_type: mlp2x_gelu
    pooling_config:
      adaptive_pool: False
      early_fusion: False
      nhead: 8
      activation: gelu
      batch_first: True
      depth: 2
    cslr2_options:
      use: True
      ckpt_path: ../cslr2_t/hrn_reproduce_withmask_4G/models/model_best.pth
      freeze: True
  llm_config:
    pretrained_llm: ${paths.llm_root}
    gradient_checkpointing_enable: True
    freeze_decoder: True
    oracle: True
    lora: True
    sub_sub: True
    lora_config:
      target_modules: ['q_proj', 'v_proj']
      lora_alpha: 16
      lora_dropout: 0.05
      r: 4
      bias: none
    tokenizer_config:
      padding_side: left
      trust_remote_code: True
      use_fast: False
      add_eos_token: True
    decoder_config:
      trust_remote_code: True
      attn_implementation: flash_attention_2
  cslr2_config:
      _target_: src.models.components.vgg_slt_modules.cslr.cslr2.CSLR2
      video_encoder:
        _target_: src.models.components.vgg_slt_modules.cslr.transformer_encoder.make_model
        vocab: 8697
        N: 6
        d_model: 768
        h: 8
        dropout: 0.1
        contrastive: True
      text_encoder:
        _target_: src.models.components.vgg_slt_modules.cslr.t5.make_sentence_model
        model_name: t5-large
        root_path: ${paths.lm_root}
      video_sequence_ll:
        _target_: torch.nn.Linear
        in_features: ${model.net.cslr2_config.video_encoder.d_model}
        out_features: 256
      video_token_ll:
        _target_: torch.nn.Linear
        in_features: ${model.net.cslr2_config.video_encoder.d_model}
        out_features: ${model.net.cslr2_config.video_sequence_ll.out_features}
      text_sentence_ll:
        _target_: torch.nn.Linear
        in_features: 1024  # size of text encoder embds
        out_features: ${model.net.cslr2_config.video_sequence_ll.out_features}
      text_word_ll:
        _target_: torch.nn.Linear
        in_features: ${model.net.cslr2_config.text_sentence_ll.in_features}
        out_features: ${model.net.cslr2_config.video_sequence_ll.out_features}
      pooling: max
      sign_ret: True
      no_video_encoder: False
      same_text_ll: False
      same_video_ll: False
      avg_baseline: True

# compile model for faster training with pytorch 2.0
compile: false
frames_path: ${paths.rgb_frames}
output_dir: ${paths.output_dir}

